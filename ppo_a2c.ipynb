{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6SXDmd7m5anf"
   },
   "source": [
    "# PPO and A2C\n",
    "\n",
    "**Note** : this script is inspired from the 1st assignment (without correction) from the RL course of the MVA master by A. Lazaric and M. Pirotta, on finite MDP and function approximation, which required to complete a partial implementation of A2C for discrete action space. It has been extended to include a different critic and actor architecture, continuous action space, and the clipped and adaptative KL losses required for PPO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "ddg4xczTsPbO",
    "outputId": "bf3678bb-1492-496b-c401-ba54a0c3411a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "try :\n",
    "    import Box2D\n",
    "except :\n",
    "    !pip install Box2D\n",
    "import pickle as pkl\n",
    "\n",
    "from config import reset_config, get_arguments\n",
    "from utils import plot_sumup\n",
    "from ppo import PPOAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "colab_type": "code",
    "id": "7OwXjxUnsUuK",
    "outputId": "c8eb7564-dbf8-4803-f772-a7909bc78d15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script running locally\n"
     ]
    }
   ],
   "source": [
    "try :\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "    %cd /content/drive/My\\ Drive/RL-PPO\n",
    "except :\n",
    "    print(\"Script running locally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "7BUBCp2NsPbc",
    "outputId": "895d6205-f69e-4ed0-a790-7fc2f51f5726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training config : \n",
      "\n",
      "{'batch_size': 128,\n",
      " 'beta_KL': 3,\n",
      " 'c1': 1,\n",
      " 'c2': 0.001,\n",
      " 'color': {'A2C_loss': (0.4, 0.7607843137254902, 0.6470588235294118),\n",
      "           'adaptative_KL_loss': (0.9882352941176471,\n",
      "                                  0.5529411764705883,\n",
      "                                  0.3843137254901961),\n",
      "           'clipped_loss': (0.5529411764705883,\n",
      "                            0.6274509803921569,\n",
      "                            0.796078431372549)},\n",
      " 'd_targ': 0.01,\n",
      " 'env': 'BipedalWalker-v3',\n",
      " 'epochs': 1,\n",
      " 'eps_clipping': 0.2,\n",
      " 'gamma': 0.99,\n",
      " 'lambda': 1,\n",
      " 'loss_name': 'clipped_loss',\n",
      " 'lr': 0.0003,\n",
      " 'max_episodes': 1000,\n",
      " 'max_steps': 300,\n",
      " 'optimize_every': 128,\n",
      " 'randomize_batch': False,\n",
      " 'reset_val': None,\n",
      " 'reward_norm': False,\n",
      " 'seed': 42,\n",
      " 'solved_reward': {'CartPole-v1': 300,\n",
      "                   'LunarLander-v2': 230,\n",
      "                   'MountainCar-v0': 300,\n",
      "                   'MountainCarContinuous-v0': 300},\n",
      " 'std': 0.5}\n"
     ]
    }
   ],
   "source": [
    "def reset_config(print_=False):\n",
    "    config = {}\n",
    "    config['env'] = \"BipedalWalker-v3\"\n",
    "\n",
    "    config['std'] = 0.5 # use constant standard deviation for continuous action space (for now)\n",
    "    config['gamma'] = 0.99 #Discount rate\n",
    "    config['lambda'] = 1 # parameter of the generalized advantage estimation\n",
    "    config['lr'] = 0.0003\n",
    "    config['eps_clipping'] = 0.2 #range : 0.1-0.3\n",
    "    config['d_targ'] = 0.01\n",
    "    config['beta_KL'] = 3\n",
    "    config['c1'] = 1 #paramter of the value function loss\n",
    "    config['c2'] = 1e-3 #entropy parameter --> 1e-4 to 1e-2\n",
    "    config[\"reward_norm\"]=False \n",
    "    config['epochs'] = 1\n",
    "    config['max_episodes'] = 1000\n",
    "    config['max_steps'] = 300\n",
    "    config['optimize_every'] = 128\n",
    "    config['batch_size'] = 128\n",
    "    config[\"randomize_batch\"]=False\n",
    "    # config['buffer_size'] = 2048 #2048 - 409600 /!\\ multiple of the batch size\n",
    "    config['loss_name'] = [\"A2C_loss\",\"adaptative_KL_loss\",\"clipped_loss\"][2]\n",
    "    config['color'] = {\"A2C_loss\":sns.color_palette(\"Set2\")[0],\"adaptative_KL_loss\":sns.color_palette(\"Set2\")[1],\"clipped_loss\":sns.color_palette(\"Set2\")[2]}\n",
    "\n",
    "    config['seed'] = 42\n",
    "    config[\"reset_val\"] = None # use to reset the environment with a custom value\n",
    "    config[\"solved_reward\"] = {'LunarLander-v2':230,\n",
    "                              'MountainCarContinuous-v0':300,\n",
    "                              'CartPole-v1':300,\n",
    "                              'MountainCar-v0':300}\n",
    "    \n",
    "    if print_== True :\n",
    "        print(\"Training config : \\n\")\n",
    "        pprint(config)\n",
    "    return config\n",
    "\n",
    "\n",
    "config = reset_config(print_=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lunar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------A2C_loss-----------------\n",
      "{'env': 'BipedalWalker-v3', 'std': 0.5, 'gamma': 0.99, 'lambda': 1, 'lr': 0.0003, 'eps_clipping': 0.2, 'd_targ': 0.01, 'beta_KL': 3, 'c1': 1, 'c2': 0.001, 'reward_norm': False, 'epochs': 1, 'max_episodes': 1000, 'max_steps': 300, 'optimize_every': 128, 'batch_size': 128, 'randomize_batch': False, 'loss_name': 'A2C_loss', 'color': {'A2C_loss': (0.4, 0.7607843137254902, 0.6470588235294118), 'adaptative_KL_loss': (0.9882352941176471, 0.5529411764705883, 0.3843137254901961), 'clipped_loss': (0.5529411764705883, 0.6274509803921569, 0.796078431372549)}, 'seed': 42, 'reset_val': None, 'solved_reward': {'LunarLander-v2': 230, 'MountainCarContinuous-v0': 300, 'CartPole-v1': 300, 'MountainCar-v0': 300}}\n",
      "Low :  [-1. -1. -1. -1.]\n",
      "High :  [1. 1. 1. 1.]\n",
      "Loss :  A2C_loss\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.4421, -0.4529,  0.1463, -0.4516]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-1.1908,  0.7022,  0.4948,  0.5968]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.1176, -0.8397, -0.6243,  1.2680]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.0230,  0.6355, -0.9185, -0.0635]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.1387, -0.1995, -0.5193, -0.1521]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.0319, -0.5802, -0.3363, -0.1273]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.9043, -0.8787, -0.4910,  0.0414]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.6638, -0.4621, -0.3027, -0.5995]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.4055, -0.0177,  0.1623,  0.4228]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.3262, -0.2170,  0.3759, -0.2788]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.2576, -0.1765,  0.3079,  1.1862]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.5356, -0.0915, -0.4709, -0.2847]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.2846, -0.3662,  0.7155, -0.6276]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.3873, -0.5266,  0.1577,  0.0649]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.0067,  0.1204, -1.0802, -0.0926]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.2784, -0.6740,  0.4658, -0.2537]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.6450,  0.0151, -0.8568, -0.0212]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.7553,  0.3095, -0.3139, -0.6139]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.2290, -0.4884,  0.2604, -0.5405]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.9010,  0.2953,  0.0656, -0.3387]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.3532,  0.6214, -1.2231, -0.9546]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.6211, -1.2021,  0.0209,  0.3255]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.4854, -0.5933, -0.5028, -1.3775]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.3786,  0.3231,  0.0690, -0.7886]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[0.5153, 0.6478, 0.3947, 0.0616]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.4202,  0.0200,  0.5987, -1.1699]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.8502, -0.1237, -0.9359, -0.7926]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.0615, -0.3701,  1.0872, -0.3882]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.6775, -0.1244,  0.0376, -0.0853]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.3879, -1.0499,  0.1516,  0.1770]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.0066,  0.5060, -0.1055,  0.3407]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.7398, -0.3643, -0.9637, -0.3063]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.4437,  0.5323,  0.8836, -0.4322]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.3245, -0.2481, -0.4543, -0.4084]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-1.4569, -0.3813,  1.1587,  0.1169]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.5635, -0.2889, -0.0500,  0.2135]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.3762, -0.7275, -0.3473, -0.4375]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.3541, -0.3928, -0.0533,  0.2370]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.3094, -0.1155, -0.0931, -0.7777]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.3423, -0.2746,  0.4232, -0.0529]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.8019, -0.5362,  0.2606, -0.2102]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.7825,  0.5211,  0.5843, -0.3096]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[1.0155, 0.1406, 0.1958, 1.4364]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.4563,  0.7093, -0.8677,  0.4538]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-1.1696,  0.1516,  0.0844,  0.4480]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.2273, -0.1388,  0.4021, -0.3084]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.0761, -0.1630, -0.2779,  0.4875]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.0847, -0.7649,  0.6585, -0.1666]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.3667,  0.6865,  0.9793, -0.6531]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.0716,  0.4282,  0.3621, -0.5150]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[0.1731, 0.4021, 0.5093, 0.3962]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.9176, -0.1964, -1.1751,  0.0793]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[0.5490, 0.0713, 0.0455, 0.0240]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.3216, -0.4429, -0.2218,  0.4341]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.1752, -0.5599,  0.0048,  0.4183]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.2712,  0.5368, -0.0985,  0.1215]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.0485,  0.5046,  0.2337, -0.2413]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.2974, -0.2605, -0.8361,  0.9168]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.5233, -0.4772,  0.1700,  0.0367]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.1214,  0.5565, -0.2822, -0.5294]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.1186, -0.3466, -0.3014,  0.6699]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.0824,  0.1716, -0.0200,  0.8269]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.1861, -0.1348, -0.7520, -0.0980]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.4675, -0.5977,  0.4652,  0.7670]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.0162,  0.7356,  0.2793, -0.2548]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.8256, -0.4950, -0.0761, -0.3701]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-1.3807, -0.0701,  0.6723, -0.0979]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.2240, -0.8250, -0.1249, -0.6307]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.2042, -0.1752, -0.7441,  0.1966]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.1832, -0.2746, -0.8541, -0.6476]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-1.3893,  0.0825, -0.6758,  0.5439]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.3992, -0.4608,  0.1060, -0.4287]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.0081,  0.1497,  0.0075, -0.2176]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.4172, -0.9918, -0.4381,  0.4747]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.5560,  0.3062, -0.3577, -0.2361]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.8517, -0.6753, -0.0578, -0.4975]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.3210, -0.4965,  0.4761, -0.4399]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.1801,  0.0472, -0.9657,  0.7842]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.4208, -1.3790, -0.0352,  0.1739]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.3363,  0.3110, -0.5335,  0.5793]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.6954,  0.1080,  0.0831,  0.5708]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[0.5366, 0.0487, 0.0522, 0.4381]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.3379, -0.2570,  0.1454,  0.7771]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.1908, -0.3580,  0.0311,  0.5561]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.0361, -0.1350, -0.1616, -0.4558]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.2832,  0.2151, -0.2440,  0.0837]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.4671, -0.3486,  0.3298,  1.0361]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.6284, -0.5144,  0.0294,  0.2891]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.4823,  0.1741, -0.1162, -0.8302]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.2398, -0.6294, -0.1259,  0.2399]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.2466, -0.4834,  0.0309,  0.0982]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.4999, -0.5378, -0.3866,  0.3265]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.1711, -0.2528,  0.3375,  0.9639]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.1618,  0.5902, -0.0552,  0.0268]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.1809,  0.2539,  0.3266,  0.4095]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.2489, -0.3458, -0.0378, -0.0195]])\n",
      "torch.Size([1, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimitri/anaconda3/envs/deeplearning/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2637, -0.4099,  1.1965,  0.1788]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.8995, -0.5492,  0.0631, -0.3321]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.0072, -0.5402,  0.2792, -0.3230]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.1824, -1.2063, -0.3466, -0.0165]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.0155, -0.0495,  0.4684, -0.3995]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 1.1547, -0.3846,  0.1924, -0.5555]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.1033, -0.5307, -0.1831,  0.2396]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.3335,  0.3119,  0.0750, -0.6508]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.2530, -0.7078, -0.3829, -0.0542]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.2922,  0.0963,  0.1928,  0.0548]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.1451,  0.1043, -0.4762,  0.4200]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.6026,  0.2309,  0.1295, -1.5395]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.4907, -0.1160,  0.4262, -0.4079]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.2247,  0.1031, -0.1858, -0.6369]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.0213,  0.0009,  0.1176,  0.0605]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.3630, -0.3541,  0.7849,  0.5064]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.7343,  0.0648,  0.4405, -0.4468]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.0225, -0.8722,  0.0424, -0.2160]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.5433, -0.2898, -0.2531, -0.5784]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.4181,  0.8986,  0.2189, -0.1517]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.2477,  1.3362, -0.1230,  0.0881]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.4695, -0.5284,  0.8194, -0.4311]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.3247,  0.6492,  0.3469, -0.6825]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.9074, -0.7356,  0.7541, -0.5930]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.3369,  0.2609, -0.3882,  0.3519]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.2122,  0.2139,  0.2154, -0.2361]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[-0.4476, -0.3163,  0.2664,  0.2281]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.3958, -0.3689,  0.8615,  0.2313]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.7121, -0.4461, -0.3081, -0.0296]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.2861, -0.7781,  0.0229, -0.4920]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.3857,  0.1552, -0.5045,  0.0788]])\n",
      "torch.Size([1, 24])\n",
      "tensor([[ 0.0640, -0.6245,  0.3380,  0.6701]])\n",
      "starting optim\n",
      "epoch 0\n",
      "here\n",
      "torch.Size([128, 24])\n",
      "torch.Size([128, 4]) bouya\n",
      "torch.Size([128, 24])\n",
      "torch.Size([128, 4]) 1\n",
      "torch.Size([4])\n",
      "torch.Size([128, 4])\n",
      "torch.Size([128, 4]) 2\n",
      "torch.Size([128])\n",
      "Nan\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimitri/anaconda3/envs/deeplearning/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "rewards_list = []\n",
    "loss_list = []\n",
    "config[\"epochs\"]=1\n",
    "#for loss in [\"clipped_loss\",\"adaptative_KL_loss\",\"A2C_loss\"]:\n",
    "for loss in [\"A2C_loss\"]:\n",
    "    print(\"-----------------\"+loss+\"-----------------\")\n",
    "    config[\"loss_name\"]=loss\n",
    "    print(config)\n",
    "    agent = PPOAgent(config)\n",
    "    \n",
    "    rewards, loss = agent.training(config[\"epochs\"], config[\"optimize_every\"], config[\"max_episodes\"], config[\"max_steps\"])\n",
    "    rewards_list.append(rewards)\n",
    "    loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_sumup(rewards_list,loss_list,config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.eye(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"BipedalWalker-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PPO_A2C.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
